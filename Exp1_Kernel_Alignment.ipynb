{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f127510-0ec7-4b5b-9b67-da331a93b1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIG\n",
    "ICL_model_name = \"tiiuae/falcon-7b\" # note: \"meta-llama/Meta-Llama-3-8B\", \"EleutherAI/pythia-6.9b\", \"tiiuae/falcon-7b\", \"meta-llama/Meta-Llama-3-70B\", \"tiiuae/falcon-40b\"\n",
    "quantized = False if ICL_model_name in [\"meta-llama/Meta-Llama-3-8B\", \"EleutherAI/pythia-6.9b\", \"tiiuae/falcon-7b\"] else True\n",
    "encoder_model_name = \"BAAI/bge-m3\"\n",
    "token = 'your token here'\n",
    "ICL_selected_token_type = \"label_words\" # \"none\" (natural ICL sample end), \"label_words\", \"last_sentence_token\"\n",
    "k = 4 # 0, 1, 2, 4, 8, 12\n",
    "dataset_index = 2 # 0, 1, 2, 3, 4, 5\n",
    "pes_dataset_index = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a57a11d-912c-485e-a9a6-8f3c0ebb0634",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "\n",
      "1 in 10 Data loaded:  GLUE-SST2 \n",
      "\n",
      "2 in 10 Data loaded:  rotten_tomatoes \n",
      "\n",
      "3 in 10 Data loaded:  financial_phrasebank \n",
      "\n",
      "4 in 10 Data loaded:  SST5 \n",
      "\n",
      "5 in 10 Data loaded:  TREC \n",
      "\n",
      "6 in 10 Data loaded:  AGNews \n",
      "\n",
      "7 in 10 Data loaded:  Subjective \n",
      "\n",
      "8 in 10 Data loaded:  tweet_eval_emotion \n",
      "\n",
      "9 in 10 Data loaded:  tweet_eval_hate \n",
      "\n",
      "10 in 10 Data loaded:  hate_speech_18 \n",
      "\n",
      "Data loaded successfully.\n",
      "\n",
      "Initializing experimentor on k = 4...\n",
      "\n",
      "Ready.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"ICL_Inference_Dynamics_Released\")\n",
    "from util import load_model_and_data, kernel_alignment, inference\n",
    "import StaICC\n",
    "\n",
    "bench = StaICC.Normal(k)\n",
    "prompts, queries = load_model_and_data.load_data_from_StaICC_experimentor(bench[dataset_index], ICL_selected_token_type)\n",
    "_, pesudo_queries = load_model_and_data.load_data_from_StaICC_experimentor(bench[pes_dataset_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a4f0d50-8688-4e0e-94e2-81a9ae6d10d0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1440b1ea60074f6fba0935730ccfc420",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s2320415/.local/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "vars_dict = vars() if \"ICL_model\" in vars() else locals()\n",
    "if \"ICL_model\" not in vars_dict:\n",
    "    ICL_model, ICL_tknz = load_model_and_data.load_ICL_model(ICL_model_name, huggingface_token = token, quantized = quantized)\n",
    "    encoder_model, encoder_tknz = load_model_and_data.load_encode_model(encoder_model_name, huggingface_token = token)\n",
    "    loaded = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8062b40-088c-4b80-940b-60ffe26c1ced",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 512/512 [01:48<00:00,  4.72it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 512/512 [00:06<00:00, 78.95it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 512/512 [00:06<00:00, 80.82it/s]\n"
     ]
    }
   ],
   "source": [
    "ICL_hidden_states = inference.ICL_inference_to_hidden_states(ICL_model, ICL_tknz, prompts)\n",
    "encoder_feature = inference.encoder_inference_to_feature(encoder_model, encoder_tknz, queries)\n",
    "pesudo_encoder_feature = inference.encoder_inference_to_feature(encoder_model, encoder_tknz, pesudo_queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc68d90b-0b81-4269-84d0-893468258ecd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 512/512 [00:01<00:00, 265.38it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 512/512 [00:01<00:00, 264.95it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 512/512 [00:01<00:00, 267.57it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 512/512 [00:01<00:00, 264.06it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 512/512 [00:01<00:00, 262.04it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 512/512 [00:01<00:00, 265.67it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 512/512 [00:01<00:00, 267.27it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 512/512 [00:01<00:00, 264.97it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 512/512 [00:01<00:00, 265.69it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 512/512 [00:01<00:00, 265.27it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 512/512 [00:01<00:00, 266.27it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 512/512 [00:01<00:00, 265.53it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 512/512 [00:01<00:00, 264.52it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 512/512 [00:01<00:00, 265.60it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 512/512 [00:01<00:00, 266.46it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 512/512 [00:01<00:00, 265.00it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 512/512 [00:01<00:00, 265.21it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 512/512 [00:01<00:00, 265.77it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 512/512 [00:01<00:00, 266.69it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 512/512 [00:01<00:00, 266.21it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 512/512 [00:01<00:00, 257.85it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 512/512 [00:01<00:00, 266.12it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 512/512 [00:01<00:00, 266.35it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 512/512 [00:01<00:00, 266.31it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 512/512 [00:01<00:00, 264.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 512/512 [00:01<00:00, 265.68it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 512/512 [00:01<00:00, 266.58it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 512/512 [00:01<00:00, 265.66it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 512/512 [00:01<00:00, 265.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 512/512 [00:01<00:00, 266.67it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 512/512 [00:01<00:00, 265.59it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 512/512 [00:01<00:00, 265.49it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 512/512 [00:01<00:00, 265.65it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 512/512 [00:01<00:00, 321.48it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 512/512 [00:01<00:00, 322.71it/s]\n"
     ]
    }
   ],
   "source": [
    "ICL_sim_graph = []\n",
    "for layer_hidden_state in ICL_hidden_states:\n",
    "    ICL_sim_graph.append(kernel_alignment.sim_graph(layer_hidden_state))\n",
    "encoder_sim_graph = kernel_alignment.sim_graph(encoder_feature)\n",
    "pesudo_encoder_sim_graph = kernel_alignment.sim_graph(pesudo_encoder_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70abf52d-b6cd-427c-b53e-4aa5f565af2f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "res = []\n",
    "pesudo_res = []\n",
    "for layer_sim_graph in ICL_sim_graph:\n",
    "    res.append(kernel_alignment.kernel_alignment(layer_sim_graph, encoder_sim_graph))\n",
    "    pesudo_res.append(kernel_alignment.kernel_alignment(layer_sim_graph, pesudo_encoder_sim_graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1fdf6a1b-83ee-43eb-9b18-38235b6360fb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21746826171875\n",
      "0.29425048828125\n",
      "0.281158447265625\n",
      "0.289215087890625\n",
      "0.29742431640625\n",
      "0.29510498046875\n",
      "0.26312255859375\n",
      "0.268585205078125\n",
      "0.258697509765625\n",
      "0.257720947265625\n",
      "0.25604248046875\n",
      "0.254119873046875\n",
      "0.25616455078125\n",
      "0.2593994140625\n",
      "0.2598876953125\n",
      "0.26123046875\n",
      "0.260040283203125\n",
      "0.25762939453125\n",
      "0.256683349609375\n",
      "0.25164794921875\n",
      "0.2479248046875\n",
      "0.2430419921875\n",
      "0.240814208984375\n",
      "0.237762451171875\n",
      "0.23712158203125\n",
      "0.237518310546875\n",
      "0.23590087890625\n",
      "0.23516845703125\n",
      "0.234130859375\n",
      "0.231048583984375\n",
      "0.229949951171875\n",
      "0.23101806640625\n",
      "0.22137451171875\n"
     ]
    }
   ],
   "source": [
    "for line in res:\n",
    "    print(line[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a104cefe-d727-4cfb-ba2b-f9d0970b197a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/tiiuae_falcon-7b,BAAI_bge-m3,label_words,4,3,8.pickle'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 34\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpickle\u001b[39;00m\n\u001b[1;32m     33\u001b[0m data_file_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../data/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m ICL_model_name\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m encoder_model_name\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m ICL_selected_token_type \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(k) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(dataset_index \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(pes_dataset_index \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.pickle\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 34\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata_file_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     35\u001b[0m     pickle\u001b[38;5;241m.\u001b[39mdump((res, pesudo_res), f)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/IPython/core/interactiveshell.py:286\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    283\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    284\u001b[0m     )\n\u001b[0;32m--> 286\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/tiiuae_falcon-7b,BAAI_bge-m3,label_words,4,3,8.pickle'"
     ]
    }
   ],
   "source": [
    "# Result file organization:\n",
    "# (\n",
    "#    res: layer_number * (alignment mean, alignment std, alignment of invidivual sample),\n",
    "#    pesudo_res: layer_number * (alignment mean, alignment std, alignment of invidivual sample),\n",
    "# )\n",
    "\n",
    "'''\n",
    "dataset index:\n",
    "\n",
    "1 in 10 Data loaded:  GLUE-SST2 \n",
    "\n",
    "2 in 10 Data loaded:  rotten_tomatoes \n",
    "\n",
    "3 in 10 Data loaded:  financial_phrasebank \n",
    "\n",
    "4 in 10 Data loaded:  SST5 \n",
    "\n",
    "5 in 10 Data loaded:  TREC \n",
    "\n",
    "6 in 10 Data loaded:  AGNews \n",
    "\n",
    "7 in 10 Data loaded:  Subjective \n",
    "\n",
    "8 in 10 Data loaded:  tweet_eval_emotion \n",
    "\n",
    "9 in 10 Data loaded:  tweet_eval_hate \n",
    "\n",
    "10 in 10 Data loaded:  hate_speech_18 \n",
    "'''\n",
    "\n",
    "import pickle\n",
    "\n",
    "data_file_name = \"../data/\" + ICL_model_name.replace('/', '_')+ \",\" + encoder_model_name.replace('/', '_')+ \",\" + ICL_selected_token_type + \",\" + str(k) + \",\" + str(dataset_index + 1) + \",\" + str(pes_dataset_index + 1) + \".pickle\"\n",
    "with open(data_file_name, 'wb') as f:\n",
    "    pickle.dump((res, pesudo_res), f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
