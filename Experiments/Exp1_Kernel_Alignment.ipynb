{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4aee4352",
   "metadata": {},
   "source": [
    "**Official implementation of paper \"Revisiting In-context Learning Inference Circuit in Large Language Models\" (ICLR 2025)**:\n",
    "\n",
    "### Source code for the Experiment 1 for Figure 2 Left and Middle.\n",
    "\n",
    "This experiment is to calculate the kernel alignment between the ICL hidden states and the sentence embedding. Control the parameters differently will make you get the Fig. 2 Left (by `ICL_selected_token_type`) and Middle (by `k`).\n",
    "\n",
    "Author: Hakaze Cho, yfzhao@jaist.ac.jp\n",
    "\n",
    "Organized and modified by: Hakaze Cho, 2025/01/26"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322f5aec",
   "metadata": {},
   "source": [
    "**Part I: Import, Define, and Load Everything**\n",
    "\n",
    "What you should do:\n",
    "1. [Cell 1] Change to the path from your working directory to the directory containing the README.md file.\n",
    "2. [Cell 2] Define your experiment parameters.\n",
    "3. Run the Cell 1 and Cell 2.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575ab82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Import libraries and change the working directory.\n",
    "\n",
    "## Import libraries\n",
    "import os\n",
    "from util import load_model_and_data, kernel_alignment, inference\n",
    "import StaICC\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "## Change the working directory\n",
    "try:\n",
    "    # Change to the path from your working directory to the directory containing the README.md file.\n",
    "    os.chdir(\"ICL_Inference_Dynamics_Released\") \n",
    "except:\n",
    "    print(\"Already in the correct directory or the directory does not exist.\")\n",
    "\n",
    "## Some definations for the plots.\n",
    "plt.style.use('default')\n",
    "plt.rc('font',family='Cambria Math')\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "plt.rcParams['font.serif'] = ['Cambria Math'] + plt.rcParams['font.serif']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f127510-0ec7-4b5b-9b67-da331a93b1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Model and huggingfacetoken configurations\n",
    "\n",
    "## The huggingface model name to be tested as the LM for ICL. \n",
    "## Recommended: \"meta-llama/Meta-Llama-3-8B\", \"EleutherAI/pythia-6.9b\", \"tiiuae/falcon-7b\", \"meta-llama/Meta-Llama-3-70B\", \"tiiuae/falcon-40b\"\n",
    "ICL_model_name = \"tiiuae/falcon-40b\" \n",
    "\n",
    "## Whether to use the quantized version of the model. \n",
    "## Recommended: Keep it default.\n",
    "quantized = False if ICL_model_name in [\"meta-llama/Meta-Llama-3-8B\", \"EleutherAI/pythia-6.9b\", \"tiiuae/falcon-7b\"] else True\n",
    "\n",
    "## The huggingface model name to be tested as the reference encoder.\n",
    "## Recommended: \"BAAI/bge-m3\"\n",
    "encoder_model_name = \"BAAI/bge-m3\"\n",
    "\n",
    "## The huggingface token to access the model. If you use the Llama model, you need to set this.\n",
    "huggingface_token = 'your token here'\n",
    "\n",
    "\n",
    "# Experiment parameters\n",
    "\n",
    "## The selected token type to calculate the KA. Alternative: \"none\" (natural ICL sample end), \"label_words\", \"last_sentence_token\".\n",
    "ICL_selected_token_type = \"label_words\" \n",
    "\n",
    "## The demonstration numbers. Recommended: 0, 1, 2, 4, 8, 12.\n",
    "k = 4 \n",
    "\n",
    "## The used dataset index from the StaICC library. Alternative: 0, 1, 2, 3, 4, 5.\n",
    "dataset_index = 2 \n",
    "\n",
    "## The used dataset index from the StaICC library for the controlled experiment. Fixed to TEE (index 6).\n",
    "pesudo_dataset_index = 7  \n",
    "\n",
    "## Force the ICL_model to reload, even the ICL_model is already in the variables. \n",
    "## Recommended: False.\n",
    "model_forced_reload = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a57a11d-912c-485e-a9a6-8f3c0ebb0634",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cell 3: Load the data and build the test inputs.\n",
    "\n",
    "benchmark = StaICC.Normal(k)\n",
    "prompts, queries = load_model_and_data.load_data_from_StaICC_experimentor(benchmark[dataset_index], ICL_selected_token_type)\n",
    "_, pesudo_queries = load_model_and_data.load_data_from_StaICC_experimentor(benchmark[pesudo_dataset_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4f0d50-8688-4e0e-94e2-81a9ae6d10d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cell 4: Load the models.\n",
    "\n",
    "vars_dict = vars() if \"ICL_model\" in vars() else locals()\n",
    "if \"ICL_model\" not in vars_dict or model_forced_reload:\n",
    "    ICL_model, ICL_tknz = load_model_and_data.load_ICL_model(ICL_model_name, huggingface_token = huggingface_token, quantized = quantized)\n",
    "    encoder_model, encoder_tknz = load_model_and_data.load_encode_model(encoder_model_name, huggingface_token = huggingface_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25e5c9a",
   "metadata": {},
   "source": [
    "**Part II: Run the Experiment**\n",
    "\n",
    "What you should do:\n",
    "\n",
    "1. Run the Cell 5 - 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8062b40-088c-4b80-940b-60ffe26c1ced",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cell 5: Get the ICL hidden states and the encoder features, also the pesudo encoder features from another dataset defined by the pesudo_dataset_index.\n",
    "\n",
    "ICL_hidden_states = inference.ICL_inference_to_hidden_states(ICL_model, ICL_tknz, prompts)\n",
    "encoder_feature = inference.encoder_inference_to_feature(encoder_model, encoder_tknz, queries)\n",
    "pesudo_encoder_feature = inference.encoder_inference_to_feature(encoder_model, encoder_tknz, pesudo_queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc68d90b-0b81-4269-84d0-893468258ecd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cell 6: Calculate the similarity map and the kernel alignment. Refer to `util/kernel_alignment.py` for more details.\n",
    "\n",
    "## Calculate the similarity map (defined as $\\delta: \\mathcal{X}\\rightarrow\\mathbb{H}^{d}$ in the Appendix A.2).\n",
    "ICL_sim_map = []\n",
    "for layer_hidden_state in ICL_hidden_states:\n",
    "    ICL_sim_map.append(kernel_alignment.sim_graph(layer_hidden_state))\n",
    "encoder_sim_map = kernel_alignment.sim_graph(encoder_feature)\n",
    "pesudo_encoder_sim_map = kernel_alignment.sim_graph(pesudo_encoder_feature)\n",
    "\n",
    "## Calculate the kernel alignment.\n",
    "### The organization of the results: res_kernel_alignment[layer_index]: (mean, std, individual_values)\n",
    "res_kernel_alignment = []\n",
    "res_reference_kernel_alignment = []\n",
    "for layer_sim_graph in ICL_sim_map:\n",
    "    res_kernel_alignment.append(kernel_alignment.kernel_alignment(layer_sim_graph, encoder_sim_map))\n",
    "    res_reference_kernel_alignment.append(kernel_alignment.kernel_alignment(layer_sim_graph, pesudo_encoder_sim_map))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69480796",
   "metadata": {},
   "source": [
    "**Part III: Plot and Save the Result**\n",
    "\n",
    "What you should do:\n",
    "\n",
    "1. Run the Cell 7 and 8. You can define your own file name and dictionary to save the result in Cell 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95dbfe0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Data preview.\n",
    "\n",
    "avg_kernel_alignment_for_plot = []\n",
    "avg_reference_kernel_alignment = []\n",
    "\n",
    "for line in res_kernel_alignment:\n",
    "    avg_kernel_alignment_for_plot.append(line[0])\n",
    "for line in res_reference_kernel_alignment:\n",
    "    avg_reference_kernel_alignment.append(line[0])\n",
    "\n",
    "plt.figure(figsize=(4, 3))\n",
    "plt.xlabel(\"Transformer Block Number\", fontsize = 12)\n",
    "plt.ylabel(\"Kernel Alignment\", fontsize = 12)\n",
    "plt.title(\"Kernel Alignment on dataset \" + str(dataset_index) + \"\\n model: \" + ICL_model_name + \"\\ntoken type: \" + ICL_selected_token_type, fontsize = 12)\n",
    "plt.plot(avg_kernel_alignment_for_plot, label=ICL_selected_token_type, color=\"blue\")\n",
    "plt.plot(avg_reference_kernel_alignment, label=\"Controlled Experiment\", color=\"gray\")\n",
    "plt.axhline(0.125, color = \"black\", linestyle = \"--\", linewidth = 1, label = \"Random Baseline\")\n",
    "plt.legend(loc = 4, prop={'size': 9})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a104cefe-d727-4cfb-ba2b-f9d0970b197a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cell 8: Save the result.\n",
    "\n",
    "# Result file organization:\n",
    "# (\n",
    "#    0: (res): layer_number * (alignment mean, alignment std, alignment of invidivual sample),\n",
    "#    1: (pesudo_res): layer_number * (alignment mean, alignment std, alignment of invidivual sample),\n",
    "# )\n",
    "\n",
    "import pickle\n",
    "\n",
    "data_file_name = \"data/\" + ICL_model_name.replace('/', '_')+ \",\" + encoder_model_name.replace('/', '_')+ \",\" + ICL_selected_token_type + \",\" + str(k) + \",\" + str(dataset_index + 1) + \",\" + str(pesudo_dataset_index + 1) + \".pickle\"\n",
    "with open(data_file_name, 'wb') as f:\n",
    "    pickle.dump((res_kernel_alignment, res_reference_kernel_alignment), f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
