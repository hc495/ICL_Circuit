{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e84c2866",
   "metadata": {},
   "source": [
    "**Official implementation of paper \"Revisiting In-context Learning Inference Circuit in Large Language Models\" (ICLR 2025)**:\n",
    "\n",
    "### The Kernel Alignment for the Copy Magnitude\n",
    "\n",
    "This experiment is to calculate the kernel alignment of the hidden states of forerunner tokens and the label token in the next layer to get the Fig. 5 (Left).\n",
    "\n",
    "Author: Hakaze Cho, yfzhao@jaist.ac.jp, 2024/08\n",
    "\n",
    "Organized, commented, and modified by: Hakaze Cho, 2025/01/26"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0c05d0",
   "metadata": {},
   "source": [
    "**Part I: Import, Define, and Load Everything**\n",
    "\n",
    "What you should do:\n",
    "1. [Cell 1] Change to the path from your working directory to the directory containing the README.md file.\n",
    "2. [Cell 2] Define your experiment parameters.\n",
    "3. Run the Cell 1 - 4.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d336f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Import libraries and change the working directory.\n",
    "\n",
    "## Change the working directory\n",
    "import os\n",
    "try:\n",
    "    # Change to the path from your working directory to the directory containing the README.md file.\n",
    "    os.chdir(\"ICL_Inference_Dynamics_Released\") \n",
    "except:\n",
    "    print(\"Already in the correct directory or the directory does not exist.\")\n",
    "\n",
    "## Import libraries\n",
    "from util import load_model_and_data, kernel_alignment, inference\n",
    "import StaICC\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "## Some definations for the plots.\n",
    "plt.style.use('default')\n",
    "plt.rc('font',family='Cambria Math')\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "plt.rcParams['font.serif'] = ['Cambria Math'] + plt.rcParams['font.serif']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5729ddfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Model and huggingfacetoken configurations\n",
    "\n",
    "## The huggingface model name to be tested as the LM for ICL. \n",
    "## Recommended: \"meta-llama/Meta-Llama-3-8B\", \"tiiuae/falcon-7b\", \"meta-llama/Meta-Llama-3-70B\", \"tiiuae/falcon-40b\"\n",
    "ICL_model_name = \"tiiuae/falcon-7b\" \n",
    "\n",
    "## Whether to use the quantized version of the model. \n",
    "## Recommended: Keep it default.\n",
    "quantized = False if ICL_model_name in [\"meta-llama/Meta-Llama-3-8B\", \"EleutherAI/pythia-6.9b\", \"tiiuae/falcon-7b\"] else True\n",
    "\n",
    "## The huggingface token to access the model. If you use the Llama model, you need to set this.\n",
    "huggingface_token = \"your token here\"\n",
    "\n",
    "# Experiment parameters\n",
    "\n",
    "## The demonstration numbers. Recommended: 0, 1, 2, 4, 8, 12.\n",
    "k = 4 \n",
    "\n",
    "## The used dataset index from the StaICC library. Alternative: 0, 1, 2, 3, 4, 5. See the README.md for more information.\n",
    "dataset_index = 2 \n",
    "\n",
    "## Force the ICL_model to reload, even the ICL_model is already in the variables. \n",
    "## Recommended: False.\n",
    "model_forced_reload = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a57a11d-912c-485e-a9a6-8f3c0ebb0634",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cell 3: Load the data and build the test inputs.\n",
    "\n",
    "bench = StaICC.Normal(k)\n",
    "load_model_and_data.set_abstract_label_space(bench[dataset_index])\n",
    "prompts, queries = load_model_and_data.load_data_from_StaICC_experimentor(bench[dataset_index], \"label_words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4f0d50-8688-4e0e-94e2-81a9ae6d10d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cell 4: Load the model.\n",
    "\n",
    "vars_dict = vars() if \"ICL_model\" in vars() else locals()\n",
    "if \"ICL_model\" not in vars_dict or model_forced_reload:\n",
    "    ICL_model, ICL_tknz = load_model_and_data.load_ICL_model(ICL_model_name, huggingface_token = huggingface_token, quantized = quantized)\n",
    "    loaded = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a0ba9e",
   "metadata": {},
   "source": [
    "**Part II: Run the Experiment**\n",
    "\n",
    "What you should do:\n",
    "\n",
    "1. Run the Cell 5 - 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8062b40-088c-4b80-940b-60ffe26c1ced",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cell 5: Get the ICL hidden states from the last 2 tokens (label token, forerunner token) of the prompt.\n",
    "\n",
    "ICL_hidden_states = inference.ICL_inference_to_multi_token_hidden_states(ICL_model, ICL_tknz, prompts, [-1, -2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc68d90b-0b81-4269-84d0-893468258ecd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cell 6: Calculate the similarity map and the kernel alignment. Refer to `util/kernel_alignment.py` for more details.\n",
    "\n",
    "## Calculate the similarity map (defined as $\\delta: \\mathcal{X}\\rightarrow\\mathbb{H}^{d}$ in the Appendix A.2) of the label tokens' hidden states, indexed by layer.\n",
    "label_token_sim_graph = []\n",
    "for layer_hidden_state in ICL_hidden_states[0]:\n",
    "    label_token_sim_graph.append(kernel_alignment.sim_graph(layer_hidden_state))\n",
    "\n",
    "## Calculate the similarity map (defined as $\\delta: \\mathcal{X}\\rightarrow\\mathbb{H}^{d}$ in the Appendix A.2) of the forerunner tokens' hidden states, indexed by layer.\n",
    "forerunner_token_sim_graph = []\n",
    "for layer_hidden_state in ICL_hidden_states[1]:\n",
    "    forerunner_token_sim_graph.append(kernel_alignment.sim_graph(layer_hidden_state))\n",
    "\n",
    "## Calculate the kernel alignment.\n",
    "### The organization of the results: res_kernel_alignment[layer_index]: (mean, std, individual_values)\n",
    "res_kernel_alignment = []\n",
    "for layer in range(len(label_token_sim_graph) - 1):\n",
    "    res_kernel_alignment.append(kernel_alignment.kernel_alignment(label_token_sim_graph[layer + 1], forerunner_token_sim_graph[layer]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a987775c",
   "metadata": {},
   "source": [
    "**Part III: Plot and Save the Result**\n",
    "\n",
    "What you should do:\n",
    "\n",
    "1. Run the Cell 7 and 8. You can define your own file name and dictionary to save the result in Cell 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57878faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Data preview.\n",
    "\n",
    "avg_kernel_alignment_for_plot = []\n",
    "\n",
    "for line in res_kernel_alignment:\n",
    "    avg_kernel_alignment_for_plot.append(line[0])\n",
    "\n",
    "plt.figure(figsize=(4, 3))\n",
    "plt.xlabel(\"Transformer Block Number\", fontsize = 12)\n",
    "plt.ylabel(\"Kernel Alignment\", fontsize = 12)\n",
    "plt.title(\"Kernel Alignment on dataset \" + str(dataset_index) + \"\\n model: \" + ICL_model_name + \", k: \" + str(k) , fontsize = 12)\n",
    "plt.plot(avg_kernel_alignment_for_plot, color=\"blue\")\n",
    "plt.axhline(0.125, color = \"black\", linestyle = \"--\", linewidth = 1, label = \"Random Baseline\")\n",
    "plt.legend(loc = 4, prop={'size': 9})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a104cefe-d727-4cfb-ba2b-f9d0970b197a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cell 8: Save the result.\n",
    "# Result file organization:\n",
    "# res_kernel_alignment[layer_number] = (alignment mean, alignment std, alignment of invidivual sample)\n",
    "\n",
    "import pickle\n",
    "\n",
    "data_file_name = \"data/\" + ICL_model_name.replace('/', '_')+ \",cross_alignment_copy,\" + \",\" + str(k) + \",\" + str(dataset_index + 1) + \",\" + \".pickle\"\n",
    "with open(data_file_name, 'wb') as f:\n",
    "    pickle.dump(res_kernel_alignment, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
