{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "899666a7",
   "metadata": {},
   "source": [
    "**Official implementation of paper \"Revisiting In-context Learning Inference Circuit in Large Language Models\" (ICLR 2025)**:\n",
    "\n",
    "### The Feature similarity on the Forerunner Token\n",
    "\n",
    "This experiment is used to visualize the feature similarity on the forerunner token, to produce the Fig. 4 in the paper.\n",
    "\n",
    "Author: Hakaze Cho, yfzhao@jaist.ac.jp, 2024/09\n",
    "\n",
    "Organized, commented, and modified by: Hakaze Cho, 2025/01/27"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174c0911",
   "metadata": {},
   "source": [
    "**Part I: Import, Define, and Load Everything**\n",
    "\n",
    "What you should do:\n",
    "1. [Cell 1] Change to the path from your working directory to the directory containing the README.md file.\n",
    "2. [Cell 2] Define your experiment parameters.\n",
    "3. Run the Cell 1 and Cell 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dae6e5a-7a85-4b8c-83b4-fa795cb7d20a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cell 1: Import libraries and change the working directory.\n",
    "\n",
    "## Change the working directory\n",
    "import os\n",
    "try:\n",
    "    # Change to the path from your working directory to the directory containing the README.md file.\n",
    "    os.chdir(\"ICL_Inference_Dynamics_Released\") \n",
    "except:\n",
    "    print(\"Already in the correct directory or the directory does not exist.\")\n",
    "\n",
    "## Import libraries\n",
    "from util import load_model_and_data, inference\n",
    "import matplotlib.pyplot as plt\n",
    "import StaICC\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "import seaborn as sns\n",
    "\n",
    "## Some definations for the plots.\n",
    "plt.style.use('default')\n",
    "plt.rc('font',family='Cambria Math')\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "plt.rcParams['font.serif'] = ['Cambria Math'] + plt.rcParams['font.serif']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f325f86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Model and huggingfacetoken configurations\n",
    "\n",
    "## The huggingface model name to be tested as the LM for ICL. \n",
    "## Recommended: \"meta-llama/Meta-Llama-3-8B\", \"tiiuae/falcon-7b\", \"meta-llama/Meta-Llama-3-70B\", \"tiiuae/falcon-40b\"\n",
    "ICL_model_name = \"tiiuae/falcon-7b\" \n",
    "\n",
    "## Whether to use the quantized version of the model. \n",
    "## Recommended: Keep it default.\n",
    "quantized = False if ICL_model_name in [\"meta-llama/Meta-Llama-3-8B\", \"EleutherAI/pythia-6.9b\", \"tiiuae/falcon-7b\"] else True\n",
    "\n",
    "## The huggingface token to access the model. If you use the Llama model, you need to set this.\n",
    "huggingface_token = \"your token here\"\n",
    "\n",
    "\n",
    "# Experiment parameters\n",
    "\n",
    "## The demonstration numbers. Recommended: 0, 1, 2, 4, 8, 12.\n",
    "k = 4 \n",
    "\n",
    "## The used dataset index from the StaICC library. Alternative: 0, 1, 2, 3, 4, 5. See the README.md for more information.\n",
    "dataset_index = 0 \n",
    "\n",
    "## The ks used in the axises for the heatmap. Recommended: [0, 1, 2, 4, 8, 12].\n",
    "ks = [0, 1, 2, 4, 8, 12]\n",
    "\n",
    "## Force the ICL_model to reload, even the ICL_model is already in the variables. \n",
    "## Recommended: False.\n",
    "model_forced_reload = False\n",
    "\n",
    "## Layer to be used in calculating the similarity. \n",
    "## Default: 16 for \"meta-llama/Meta-Llama-3-8B\" and \"tiiuae/falcon-7b\"; 24 for \"tiiuae/falcon-40b\" and \"meta-llama/Meta-Llama-3-70B\". \n",
    "layer_used = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4f0d50-8688-4e0e-94e2-81a9ae6d10d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cell 3: Load the models.\n",
    "\n",
    "vars_dict = vars() if \"ICL_model\" in vars() else locals()\n",
    "if \"ICL_model\" not in vars_dict or model_forced_reload:\n",
    "    ICL_model, ICL_tknz = load_model_and_data.load_ICL_model(ICL_model_name, huggingface_token = huggingface_token, quantized = quantized)\n",
    "    loaded = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253c7c9f",
   "metadata": {},
   "source": [
    "**Part II: Run the Experiment**\n",
    "\n",
    "What you should do:\n",
    "\n",
    "1. Run the Cell 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8062b40-088c-4b80-940b-60ffe26c1ced",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cell 4: Collect the ICL hidden states in the forerunner tokens for the different k values.\n",
    "\n",
    "ICL_hidden_states_indexed_by_k = {}\n",
    "\n",
    "for k in ks:\n",
    "    print(\"k = \", k)\n",
    "    bench = StaICC.Normal(k)\n",
    "    prompts, queries = load_model_and_data.load_data_from_StaICC_experimentor(bench[dataset_index], \"none\")\n",
    "    ICL_hidden_states = inference.ICL_inference_to_hidden_states(ICL_model, ICL_tknz, prompts)\n",
    "    ICL_hidden_states_indexed_by_k[k] = ICL_hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2297fe88",
   "metadata": {},
   "outputs": [],
   "source": [
    "ICL_hidden_states_indexed_by_k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89432806",
   "metadata": {},
   "source": [
    "**Part III: Plot and Save the Result**\n",
    "\n",
    "What you should do:\n",
    "\n",
    "1. Run the Cell 5 - 7. You can define your own file name and dictionary to save the result in Cell 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6392b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Plot the blue heatmap with the same query.\n",
    "\n",
    "heat_map_content_with_the_same_query = np.zeros((len(ks), len(ks)))\n",
    "\n",
    "for i in range(len(ks)):\n",
    "    for j in range(i + 1):\n",
    "        temp = []\n",
    "        for sample_index in range(len(ICL_hidden_states_indexed_by_k[ks[i]][layer_used])):\n",
    "            A = ICL_hidden_states_indexed_by_k[ks[i]][layer_used][sample_index]\n",
    "            B = ICL_hidden_states_indexed_by_k[ks[j]][layer_used][sample_index]\n",
    "            temp.append(np.dot(A,B)/(norm(A)*norm(B)))\n",
    "        heat_map_content_with_the_same_query[i][j] = np.mean(temp)\n",
    "\n",
    "mask = []\n",
    "for i in range(len(heat_map_content_with_the_same_query)):\n",
    "    temp_mask = [0] * (i+1) + [1] * (len(heat_map_content_with_the_same_query)-i-1)\n",
    "    mask.append(temp_mask)\n",
    "\n",
    "plt.figure(figsize=(3, 3))\n",
    "sns.heatmap(\n",
    "    heat_map_content_with_the_same_query, \n",
    "    vmin = 0,\n",
    "    vmax = 1,\n",
    "    mask = np.array(mask), \n",
    "    annot=True, \n",
    "    cbar=False,\n",
    "    linewidths=0.5,\n",
    "    cmap = \"PuBu\",\n",
    "    xticklabels = ks,\n",
    "    yticklabels = ks\n",
    ")\n",
    "plt.xlabel(\"Query Location\", fontsize = 12)\n",
    "plt.ylabel(\"Query Location\", fontsize = 12)\n",
    "plt.title(\"Feature similarity on dataset \" + str(dataset_index) + \"\\n model: \" + ICL_model_name, fontsize = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb90e453",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Plot the orange heatmap with the different query.\n",
    "\n",
    "heat_map_content_with_the_same_query = np.zeros((len(ks), len(ks)))\n",
    "\n",
    "for i in range(len(ks)):\n",
    "    for j in range(i + 1):\n",
    "        temp = []\n",
    "        for sample_index in range(len(ICL_hidden_states_indexed_by_k[ks[i]][layer_used])):\n",
    "            print('\\r' + str(i) + str(j) + str(sample_index), flush=True, end=\"\")\n",
    "            for sample_index2 in range(len(ICL_hidden_states_indexed_by_k[ks[i]][layer_used])):\n",
    "                if sample_index == sample_index2:\n",
    "                    continue\n",
    "                A = ICL_hidden_states_indexed_by_k[ks[i]][layer_used][sample_index]\n",
    "                B = ICL_hidden_states_indexed_by_k[ks[j]][layer_used][sample_index2]\n",
    "                temp.append(np.dot(A,B)/(norm(A)*norm(B)))\n",
    "        heat_map_content_with_the_same_query[i][j] = np.mean(temp)\n",
    "\n",
    "mask = []\n",
    "for i in range(len(heat_map_content_with_the_same_query)):\n",
    "    temp_mask = [0] * (i+1) + [1] * (len(heat_map_content_with_the_same_query)-i-1)\n",
    "    mask.append(temp_mask)\n",
    "\n",
    "plt.figure(figsize=(3, 3))\n",
    "sns.heatmap(\n",
    "    heat_map_content_with_the_same_query, \n",
    "    vmin = 0,\n",
    "    vmax = 1,\n",
    "    mask = np.array(mask), \n",
    "    annot=True, \n",
    "    cbar=False,\n",
    "    linewidths=0.5,\n",
    "    cmap = \"Oranges\",\n",
    "    xticklabels = ks,\n",
    "    yticklabels = ks\n",
    ")\n",
    "plt.xlabel(\"Query Location\", fontsize = 12)\n",
    "plt.ylabel(\"Query Location\", fontsize = 12)\n",
    "plt.title(\"Feature similarity on dataset \" + str(dataset_index) + \"\\n model: \" + ICL_model_name, fontsize = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a104cefe-d727-4cfb-ba2b-f9d0970b197a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cell 7: Save the hidden states to a pickle file.\n",
    "# Result file organization:\n",
    "# ICL_hidden_states_indexed_by_k[k] is a list of hidden states, with index aligned with the sample number, for the k-th query location.\n",
    "\n",
    "import pickle\n",
    "\n",
    "data_file_name = \"data/\" + ICL_model_name.replace('/', '_') + \",ICLFeatures,\" + str(k) + ',' + str(dataset_index + 1) + \".pickle\"\n",
    "with open(data_file_name, 'wb') as f:\n",
    "    pickle.dump(ICL_hidden_states_indexed_by_k, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
