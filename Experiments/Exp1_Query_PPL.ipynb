{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89e8d1b3",
   "metadata": {},
   "source": [
    "**Official implementation of paper \"Revisiting In-context Learning Inference Circuit in Large Language Models\" (ICLR 2025)**:\n",
    "\n",
    "### The LM Loss of the Query on the ICL Model\n",
    "\n",
    "This experiment is to calculate the LM loss of the query on the ICL model, to get the x-axis of Fig. 2 Right. Augmented with the individual kernel alignment data from the results of `Exp1_Kernel_Alignment.ipynb`, you can get the Fig. 2 Right.\n",
    "\n",
    "Author: Hakaze Cho, yfzhao@jaist.ac.jp, 2024/08\n",
    "\n",
    "Organized, commented, and modified by: Hakaze Cho, 2025/01/26"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1355a03b",
   "metadata": {},
   "source": [
    "**Part I: Import, Define, and Load Everything**\n",
    "\n",
    "What you should do:\n",
    "1. [Cell 1] Change to the path from your working directory to the directory containing the README.md file.\n",
    "2. [Cell 2] Define your experiment parameters.\n",
    "3. Run the Cell 1 - 4.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ce8dd22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Import libraries and change the working directory.\n",
    "\n",
    "## Change the working directory\n",
    "import os\n",
    "try:\n",
    "    # Change to the path from your working directory to the directory containing the README.md file.\n",
    "    os.chdir(\"ICL_Inference_Dynamics_Released\") \n",
    "except:\n",
    "    print(\"Already in the correct directory or the directory does not exist.\")\n",
    "\n",
    "## Import libraries\n",
    "from util import load_model_and_data, inference\n",
    "import StaICC\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "## Some definations for the plots.\n",
    "plt.style.use('default')\n",
    "plt.rc('font',family='Cambria Math')\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "plt.rcParams['font.serif'] = ['Cambria Math'] + plt.rcParams['font.serif']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95dd46d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Model and huggingfacetoken configurations\n",
    "\n",
    "## The huggingface model name to be tested as the LM for ICL. \n",
    "## Recommended: \"meta-llama/Meta-Llama-3-8B\", \"EleutherAI/pythia-6.9b\", \"tiiuae/falcon-7b\", \"meta-llama/Meta-Llama-3-70B\", \"tiiuae/falcon-40b\"\n",
    "ICL_model_name = \"tiiuae/falcon-7b\" \n",
    "\n",
    "## Whether to use the quantized version of the model. \n",
    "## Recommended: Keep it default.\n",
    "quantized = False if ICL_model_name in [\"meta-llama/Meta-Llama-3-8B\", \"EleutherAI/pythia-6.9b\", \"tiiuae/falcon-7b\"] else True\n",
    "\n",
    "## The huggingface token to access the model. If you use the Llama model, you need to set this.\n",
    "huggingface_token = \"your token here\"\n",
    "\n",
    "\n",
    "# Experiment parameters\n",
    "\n",
    "## The demonstration numbers. Recommended: 0, 1, 2, 4, 8, 12.\n",
    "k = 4 \n",
    "\n",
    "## The used dataset index from the StaICC library. Alternative: 0, 1, 2, 3, 4, 5. See the README.md for more information.\n",
    "dataset_index = 2 \n",
    "\n",
    "## Force the ICL_model to reload, even the ICL_model is already in the variables. \n",
    "## Recommended: False.\n",
    "model_forced_reload = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f80c8eb-0a65-4ccd-a4f2-6daa6167f5d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cell 3: Load the data and build the test inputs.\n",
    "\n",
    "bench = StaICC.Normal(k)\n",
    "_, queries = load_model_and_data.load_data_from_StaICC_experimentor(bench[dataset_index], \"none\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a716c6-d637-49ed-bbf4-9ce9a99992cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cell 4: Load the model.\n",
    "\n",
    "vars_dict = vars() if \"ICL_model\" in vars() else locals()\n",
    "if \"ICL_model\" not in vars_dict or model_forced_reload:\n",
    "    ICL_model, ICL_tknz = load_model_and_data.load_ICL_model(ICL_model_name, huggingface_token = huggingface_token, quantized = quantized)\n",
    "    loaded = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8500476",
   "metadata": {},
   "source": [
    "**Part II: Run the Experiment**\n",
    "\n",
    "What you should do:\n",
    "\n",
    "1. Run the Cell 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ee657f-9b74-465e-81c4-24b7e8728f59",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate the LM loss of the query.\n",
    "\n",
    "ppls = inference.get_ppl(ICL_model, ICL_tknz, queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1756e99d",
   "metadata": {},
   "source": [
    "**Part III: Plot and Save the Result**\n",
    "\n",
    "What you should do:\n",
    "\n",
    "1. Run the Cell 6. You can define your own file name and dictionary to save the result in Cell 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f4f302-94cc-4c82-8fc7-dce13dbb464b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cell 8: Save the result.\n",
    "# Result file organization:\n",
    "# list[sample_index] = the LM loss of the sample. Index aligned with the results from the `Exp1_Kernel_Alignment.ipynb`.\n",
    "\n",
    "import pickle\n",
    "\n",
    "data_file_name = \"data/\" + ICL_model_name.replace('/', '_')+ \",PPL,\" + str(dataset_index + 1) + \".pickle\"\n",
    "with open(data_file_name, 'wb') as f:\n",
    "    pickle.dump([ppl for ppl in ppls], f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
